<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Week1</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(145, 145, 142, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(187, 132, 108, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(215, 129, 58, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 148, 51, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(108, 155, 125, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(91, 151, 189, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(167, 130, 195, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(205, 116, 159, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(225, 111, 100, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(145, 145, 142, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(187, 132, 108, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(215, 129, 58, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 148, 51, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(108, 155, 125, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(91, 151, 189, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(167, 130, 195, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(205, 116, 159, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(225, 111, 100, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="ec36eb25-55c4-4917-94e8-3ac3ed8e50b1" class="page sans"><header><h1 class="page-title">Week1</h1></header><div class="page-body"><nav id="4a123c44-31eb-49d2-bbd2-0e742bc0404f" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#afef38ce-908f-4a49-a2a4-1c7b5937039e">CH10 - 케라스를 사용한 인공 신경망 소개</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#bbb1bd47-cc5c-462d-8685-ffc92f90874b">10.1 생물학적 뉴런에서 인공 뉴런까지</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#bbc0d943-3833-4dab-a5a5-74e49051d025">10.1.1 생물학적 뉴런</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#fea5746b-97d3-464b-820d-cc8eae4ac80c">10.1.2 뉴런을 사용한 논리 연산</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#f07c2133-8de7-4b8b-a5fa-21a7365b8204">10.1.3 퍼셉트론</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#7ed3f40d-e8d2-479a-a467-f7e088151dd4">10.1.4 다층 퍼셉트론과 역전파</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#b26f0b45-894c-4eea-9421-f8ebead47b1e">10.1.5 회귀를 위한 다층 퍼셉트론</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#fa50fc86-ecfb-433a-850c-9b504d0e26b2">10.1.6 분류를 위한 다층 퍼셉트론</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#b1422828-8659-4d3d-8b44-3b627edcc491">10.2 케라스로 다층 퍼셉트론 구현하기</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#2e92c884-690b-4e72-9207-3f5d267ef311">10.2.1 텐서플로 2 설치</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#12fc1ab8-48ab-4542-a002-74923a0cfd1f">10.2.2 시퀀셜 API를 사용하여 이미지 분류기 만들기</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#5da42672-dd9d-48db-97f7-30d37bb58da0">10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#6369e74c-6a45-48f9-b428-7a7f12bc3f59">10.2.4 함수형 API를 사용해 복잡한 모델 만들기</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#05fde0f5-0198-4f39-b5a3-17fc577300f3">10.2.5 서브클래싱 API로 동적 모델 만들기</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#031af980-db17-4b09-898a-2aa83cbfe1cf">10.2.6 모델 저장과 복원</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#30ae6cb0-f1e3-46bd-8dfe-47f5b73f6bc8">10.2.7 콜백 사용하기</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#861db455-fdeb-42e5-9cb7-67518b80f493">10.2.8 텐서보드를 사용해 시각화하기</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#7064e125-56f4-4e3c-892b-f82cd4f8bfe4">10.3 신경망 하이퍼파라미터 튜닝하기</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#21fdc8e9-f503-472b-bb64-3fcec162534c">10.3.1 은닉층 개수</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#790b0627-bc1c-428f-b0f4-0416887eedfa">10.3.2 은닉층의 뉴런 개수</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#edfc3f7e-2c84-4ee0-bf4a-f26cd6450dc8">10.3.3 학습률, 배치 크기 그리고 다른 하이퍼파라미터</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0b1dade7-3890-483a-a4e9-5ef7b5ffb948">10.4 연습문제</a></div></nav><hr id="a3cfd9f4-3300-46ad-a848-9c5b7e9fafaf"/><h1 id="afef38ce-908f-4a49-a2a4-1c7b5937039e" class="block-color-gray_background">CH10 - 케라스를 사용한 인공 신경망 소개</h1><p id="5aa580e6-827e-4141-9c68-7900679ded82" class="">인공 신경망(ANN) ~ 인공 신경망은 딥러닝의 핵심</p><p id="8ea32066-7896-448f-8068-3c48eafc72b3" class="">다층 퍼셉트론(MLP)에 대해서도 알아보자</p><p id="530e6001-4b92-4138-848e-f6c2fd18379b" class="">
</p><h2 id="bbb1bd47-cc5c-462d-8685-ffc92f90874b" class="block-color-gray_background">10.1 생물학적 뉴런에서 인공 뉴런까지</h2><p id="482ba113-db1f-45ff-945b-efb9593e1b78" class="">현재 인공 신경망의 재부흥</p><p id="93cc2003-da09-4dd6-9334-aaa03e6db451" class="">&lt;근거&gt;</p><ul id="792eb597-89d2-4886-bc72-78a1b41ae2a6" class="bulleted-list"><li style="list-style-type:disc">방대한 데이터 양</li></ul><ul id="b66e0d20-2313-4603-a8ff-2e89fa068f26" class="bulleted-list"><li style="list-style-type:disc">하드웨어의 발전</li></ul><ul id="859bea1c-27f9-45bd-ad1a-334fa8212771" class="bulleted-list"><li style="list-style-type:disc">훈련 알고리즘 향상</li></ul><ul id="553ddf53-af00-4b22-a7e4-8b103ac385fa" class="bulleted-list"><li style="list-style-type:disc">이론상 제한 → 실제로는 문제 X</li></ul><ul id="2550646e-1f0b-47c7-9b08-a85bb7a8ab79" class="bulleted-list"><li style="list-style-type:disc">투자와 진보의 선순환</li></ul><h3 id="bbc0d943-3833-4dab-a5a5-74e49051d025" class="block-color-blue_background">10.1.1 생물학적 뉴런</h3><figure id="8e3cc69f-4e08-4832-93a2-7c2b56187454" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled.png"><img style="width:432px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled.png"/></a></figure><h3 id="fea5746b-97d3-464b-820d-cc8eae4ac80c" class="block-color-blue_background">10.1.2 뉴런을 사용한 논리 연산</h3><p id="f6bfb815-901f-40e0-b263-fc52ec7a38c8" class="">매컬러와 피츠의 인공 뉴런 ~ 하나 이상의 이진 입력과 이진 출력 하나를 가짐</p><p id="5006a7ce-67d7-405c-95aa-6e2b9fbe0972" class="">논리 명제도 계산 가능</p><h3 id="f07c2133-8de7-4b8b-a5fa-21a7365b8204" class="block-color-blue_background">10.1.3 퍼셉트론</h3><p id="4131f35c-3734-4068-a42b-51fbce864242" class="">가장 간단한 인공신경망 구조 ~ TLU(Threshold Logic Unit)이라는 인공 뉴런을 기반으로 함</p><p id="c034c9a3-19a4-4f9a-836e-4dfec937314e" class="">입력 값: 이진값 아닌 어떤 숫자</p><p id="ac1e0c62-eb6f-48a8-92e1-40715a5a27e1" class="">입력 연결은 가중치와 연관 ~ 입력의 가중치 합을 계산한 뒤, 계산된 합에 step function을 적용하여 결과 출력</p><p id="6e774e49-1d13-4f60-84d4-a593b041edfd" class=""><mark class="highlight-gray"><strong>가중치 합 계산</strong></mark> → <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub><mo>=</mo><msup><mi>x</mi><mi>T</mi></msup><mi>w</mi></mrow><annotation encoding="application/x-tex">z = w_1x_1 + w_2x_2 + ... + w_nx_n =  x^Tw</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">...</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span></span><span>﻿</span></span></p><p id="02f51159-3969-4e7d-94fb-607203ccb046" class=""><mark class="highlight-gray"><strong>계단 함수 적용</strong></mark> → <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>w</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_w(x) = step(z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span></p><p id="6d596c71-4306-43ad-b48b-b93b7b803333" class="">헤비사이드 계단 함수 ~ 가장 널리 사용되는 계단 함수</p><p id="01049e12-f495-4263-bf9d-934c8d9a4f77" class="">
</p><p id="0df0447d-3a5b-4b5e-a486-2facf141c01c" class="">완전 연결층(밀집층): 한 층에 있는 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있을 때</p><p id="155acf7b-bbcc-4b53-86b0-00d7295b9e28" class="">입력 뉴런: 퍼셉트론의 입력 ~ 입력층: 모든 입력 뉴런</p><p id="5b68d6ca-7d64-4bae-8f74-5ff8b8fe9ad5" class="">편향: 항상 1을 출력</p><figure id="207783c5-7e43-45a4-98dc-36901424cb43" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%201.png"><img style="width:384px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%201.png"/></a></figure><p id="847fc747-930d-426e-a7b9-e4e7d8f0e4ad" class=""><mark class="highlight-blue"><strong>완전 연결층 출력 계산</strong></mark> → <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>W</mi></msub><msub><mo separator="true">,</mo><mi>b</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>ϕ</mi><mo stretchy="false">(</mo><mi>X</mi><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_W,_b(X) = \phi(XW + b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct"><span class="mpunct">,</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span></p><p id="e25260ff-5b89-4eac-b820-0f155d7228cb" class=""><mark class="highlight-gray"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">ϕ</span></span></span></span></span><span>﻿</span></span></mark><mark class="highlight-gray"> : 활성화 함수 activation function (인공 뉴런이 TLU일 경우 이 함수는 계단 함수)</mark></p><p id="98e67fe8-e460-4ebc-b88c-62c525297c00" class="">헤브의 규칙(헤브 학습): 두 뉴런이 동시에 활성화될 때마다 이들 사리의 연결 가중치가 증가하는 경향이 있다</p><p id="fd28bff1-8d4b-407d-85b1-d43b12ef5c0b" class="">
</p><p id="84a6a5f1-b80c-4df9-9812-069cd303a676" class="">&lt;<strong>퍼셉트론 학습 규칙&gt;</strong></p><ul id="538de53f-91e6-4250-b6aa-523054ec250d" class="bulleted-list"><li style="list-style-type:disc">네트워크가 예측할 때 만드는 오차 반영 → 변형된 규칙 사용하여 훈련</li></ul><ul id="185e5f02-de96-4c63-b1a8-76ba79e91f30" class="bulleted-list"><li style="list-style-type:disc">오차가 감소되도록 연결 강화</li></ul><ul id="e5e1369f-8991-4ac6-a822-bb2bf105cf4b" class="bulleted-list"><li style="list-style-type:disc">한번에 한개의 샘플 주입 → 각 샘플에 대한 예측 생성</li></ul><ul id="dfce759f-7403-4465-ad28-b706e8a68c63" class="bulleted-list"><li style="list-style-type:disc">잘못된 예측을 하는 출력 뉴런 → 올바른 예측을 할 수 있도록 연결된 가중치 강화</li></ul><ul id="1fcfd1ef-9abb-4a63-84c8-6aea9a9cdc46" class="bulleted-list"><li style="list-style-type:disc"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub><msubsup><mo separator="true">,</mo><mi>j</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi><mtext> </mtext><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><msub><mi>w</mi><mi>i</mi></msub><msub><mo separator="true">,</mo><mi>j</mi></msub><mo>+</mo><mtext> </mtext><mi>η</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mtext> </mtext><mo>−</mo><mtext> </mtext><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>j</mi></msub><mo stretchy="false">)</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_i,_j^{(next\ step)} = w_i,_j +\ \eta(y_i\ -\ \hat{y}_j)x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4577719999999998em;vertical-align:-0.4129719999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct"><span class="mpunct">,</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight"><span class="mtight"> </span></span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">p</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4129719999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct"><span class="mpunct">,</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">+</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></li></ul><p id="d49c3761-728d-42e6-9679-4c3be21fe980" class="">→ 훈련 샘플이 선형적으로 구분될 수 있으며 이 알고리즘에 수렴한다</p><p id="54411c22-d9fe-40c3-9499-f40fa8d0b9f0" class="">→ 퍼셉트론 수렴 이론</p><pre id="374c0e79-edeb-4767-a471-dad948df3459" class="code"><code>import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import Perceptron

iris = load_iris()
x = iris.data[:,(2,3)]
y = (iris.target == 0).astype(np.int)

per_clf = Perceptron()
per_clf.fit(x,y)

y_pred = per_clf.predict([[2,0.5]])</code></pre><p id="5733fe52-ed28-4b16-b99c-8089002d14ad" class="">경사 하강법과 매우 유사</p><p id="7331d50e-b60b-4563-a26a-b858d76cd90f" class="">고정된 임계값을 기준으로 예측</p><p id="3cb26881-bf51-480c-ae50-496bd6b9ad42" class="">
</p><p id="a08060d4-8e88-4df8-b84f-49ccbf37a5ed" class="">퍼셉트론의 심각한 약점 → 일부 간단한 문제(XOR: 베타적 논리합 분류 문제) 해결 불가</p><p id="fded8d0f-befa-4325-9e39-34c44a063a15" class="">⇒ 여러 개 쌓아 올리면 일부 제약 감소: <mark class="highlight-blue"><strong>다층 퍼셉트론(MLP) → XOR 해결 가능!</strong></mark></p><h3 id="7ed3f40d-e8d2-479a-a467-f7e088151dd4" class="block-color-blue_background">10.1.4 다층 퍼셉트론과 역전파</h3><figure id="c5121cf2-d661-4afa-bb3f-27675b6e4726" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%202.png"><img style="width:384px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%202.png"/></a></figure><p id="236cb600-d8b5-4356-a1c0-09d03ffd228f" class="">입력층과 가까운 층: 하위 층 // 출력층과 가까운 층: 상위 층</p><p id="d82e22c5-a6e8-415f-8555-472e330ec88e" class="">출력층을 제외하고 모든 층은,</p><ul id="1afb3260-2319-4126-870c-71f11b24e394" class="bulleted-list"><li style="list-style-type:disc"> 편향 뉴런을 포함/</li></ul><ul id="13be63ab-312f-4118-a50a-e23af487c9b9" class="bulleted-list"><li style="list-style-type:disc">다음 층과 완전히 연결되어 있음</li></ul><p id="5f1209b0-fb01-42f1-a5ae-c5ef37add818" class="">신호는 한 방향으로만 흐름 →<mark class="highlight-blue"><strong> 피드포워드 신경망(FNN) </strong></mark>구조에 속함</p><p id="2a098a27-57a1-4474-b77e-3327badc8c0e" class="">은닉층을 여러개 쌓아 올린 인공 신경망: 심층 신경망(DNN)</p><p id="a75084fe-8e20-4c58-a828-741a1ca042fe" class="">
</p><p id="32ee802f-8c01-4237-936c-bd59abc50f05" class="">다층 퍼셉트론을 훈련할 방법 → <mark class="highlight-blue"><strong>역전파</strong></mark>(backpropagation) <strong>훈련 알고리즘</strong> 등장</p><p id="6f1215ec-6864-4374-8465-d7ca350c1963" class="">= 경사 하강법: 그레디언트를 자동으로 계산 → <mark class="highlight-gray"><strong>자동 미분</strong></mark></p><p id="0fd7ee8c-1033-439b-98f7-809cc74a53f3" class="">
</p><p id="40bb6c55-b822-4fac-ab77-cd46f694735a" class=""><mark class="highlight-blue_background"><strong>&lt;역전파 훈련 알고리즘&gt;</strong></mark></p><p id="fe8edd38-5fe2-47f5-94ed-e4ce913eb831" class="">훈련 세트 처리 반복 → 각 반복: 에포크(<mark class="highlight-blue">epoch</mark>)</p><ol type="1" id="822dfdda-c213-4c53-8f47-bba3a885586c" class="numbered-list" start="1"><li>정방향 계산: 마지막 층인 출력층의 출력을 계산할 때까지 계속해서 계산</li></ol><ol type="1" id="26f04c1d-85af-4fb7-a22f-216db6c48337" class="numbered-list" start="2"><li>손실 함수를 사용하여 네트워크의 출력 오차 측정</li></ol><ol type="1" id="159d019e-9862-425c-a696-78687615f6a5" class="numbered-list" start="3"><li>출력 연결이 오차에 기여하는 정도 계산(연쇄 법칙 chain rule 적용)</li></ol><ol type="1" id="1496cb72-dfe3-4e62-a269-b6cfcffec9b2" class="numbered-list" start="4"><li>이전 층의 연결 가중치가 오차에 기여하는 정도 계산  → 입력층에 도달할 때까지 역방향 계산</li></ol><ol type="1" id="94e13e18-54d8-4a50-b08d-3b7c3a4e6cb4" class="numbered-list" start="5"><li>경사 하강법 수행 → 모든 연결 가중치 수정</li></ol><p id="a43da6ef-7502-4cfc-8fea-e8423b1daa34" class=""><mark class="highlight-orange">☑️ 은닉층의 연결 가중치를 랜덤하게 초기화하는 것이 중요!</mark></p><p id="60dbddd0-3d16-4dd6-ba9d-fd7cf2839aa7" class="">
</p><p id="a5907c4a-dc9a-4bc6-ab15-ac382f9d2f26" class="">다층 퍼셉트론의 중요한 변화‼️</p><p id="63194280-c375-495d-8ce1-5a9b4b10dc72" class="">계단 함수 → <strong>시그모이드(로지스틱)함수로 변경 → </strong><strong><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mo>−</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(z) = \frac{1}{(1+exp(-z))}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.365108em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mclose mtight">))</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span></strong></p><p id="4f6c2e57-12ee-41b3-9af9-88cbb0dc035c" class="">&lt;활성화 함수&gt;</p><ul id="fe3fcac8-3e89-4cb2-b6e4-39d0560bf064" class="bulleted-list"><li style="list-style-type:disc">시그모이드 함수</li></ul><ul id="73e4d958-3d01-4cf1-84ce-38a7ce02a473" class="bulleted-list"><li style="list-style-type:disc">하이퍼볼릭 탄젠트 함수</li></ul><ul id="3ec50b07-602f-47e6-bad0-536326febb95" class="bulleted-list"><li style="list-style-type:disc">ReLU 함수</li></ul><figure id="18182467-b980-4c69-a26f-41156321ec1a" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%203.png"><img style="width:480px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%203.png"/></a></figure><p id="b92f439f-3a6a-49e5-8faa-210a1470d199" class="">Q. 활성화 함수는 왜 필요할까? </p><p id="47f08d0d-3878-4ca9-97b9-4dc813bb0db1" class="">A. 선형 변환을 여러 개 연결해도 얻을 수 있는 것은 선형 변환 뿐
     따라서, 층 사이 비선형성을 추가하지 않으면 아무리 많은 층을 쌓아도 하나의 층과 동일</p><h3 id="b26f0b45-894c-4eea-9421-f8ebead47b1e" class="block-color-blue_background">10.1.5 회귀를 위한 다층 퍼셉트론</h3><p id="52a7f25d-de82-4f4f-bed4-9767ce6e19fe" class="">회귀 작업을 할 때 다층 퍼셉트론 사용</p><p id="55e5ea59-942a-47da-b5c6-d8f6e1aa36d5" class="">일반 회귀(하나의 값 예측), 출력: 예측된 값 → 하나의 출력 뉴런이 필요</p><p id="b3aecf36-36ec-45a9-ab78-77afbce4c7ef" class="">다변량 회귀(동시에 여러 값 예측) → 출력 차원마다 출력 뉴런 필요</p><p id="5ee16e7f-f8ee-498c-9707-43ae84745e55" class="">
</p><p id="30364aac-ec7b-48e7-b9f3-6158ffa5b119" class="">회귀용 다층 퍼셉트론을 만들 때, 일반적으로 활성화 함수를 사용 X</p><p id="245cb203-c4c2-4984-9f55-9c30ece229b1" class=""><mark class="highlight-orange_background">출력이 항상 양수이다!</mark> → 출력층에 ReLU 활성화 함수 사용 or softplus 함수 사용</p><p id="4b0377c1-7c5c-498a-8085-d34866a1067f" class=""><strong><mark class="highlight-gray">❉ softplus 함수:  </mark></strong><strong><mark class="highlight-gray"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">log(1+exp(z))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">))</span></span></span></span></span><span>﻿</span></span></mark></strong></p><p id="1b128bd9-500d-4f5b-a7eb-9a9597bc0f73" class=""><mark class="highlight-orange_background">어떤 범위 안의 값을 예측하고 싶다!</mark> → 시그모이드 or 하이퍼볼릭 탄젠트 함수 사용</p><p id="170c45b6-15e0-4625-94da-e1c3cb9e5751" class="">
</p><p id="fc8a1780-e78b-4d7c-ab6c-2714423051b8" class="">loss function: MSE // 이상치가 많으면 MAE, Huber(MSE와 MAE을 조합한 것)</p><figure id="03f877a3-24bd-41ed-9225-32a3f514f5a2" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%204.png"><img style="width:1804px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%204.png"/></a><figcaption>회귀 MLP의 전형적인 구조</figcaption></figure><h3 id="fa50fc86-ecfb-433a-850c-9b504d0e26b2" class="block-color-blue_background">10.1.6 분류를 위한 다층 퍼셉트론</h3><p id="14c3d0fe-d94f-4cb0-94d9-a014184990d8" class="">이진 분류 → 시그모이드 활성화 함수를 가진 하나의 출력 뉴런만 필요</p><p id="11cb0631-e6ef-4272-b300-d1ce6b7bc72e" class="">출력은 0과 1사이의 실수 → 양성 클래스에 대한 예측 확률로 해석</p><p id="e75e7f4e-7a25-4c61-acba-e0e3b09c9c85" class="">                                         (음성 클래스에 대한 예측 확률 = 1- 양성 클래스에 대한 예측 확률)</p><p id="7c956d4d-18e5-402c-a662-01fbcdcf2897" class="">
</p><p id="4702f7c1-44b8-42dd-b0b3-a55c01fb906b" class="">다층 퍼셉트론: 다중 레이블 이진 분류 문제 처리에 용이(ex. 메일이 스팸인지 아닌지 + 긴급한 것인지 아닌지)</p><p id="47414891-554e-4210-9a2c-88520a484f31" class="">⇒ 긴급하지 않은 메일 / 긴급한 메일 / 긴급하지 않은 스팸 메일 / 긴급한 스팸 메일(오류로 추정)</p><ul id="5de2d393-a76c-496f-bddb-ec6d0893176b" class="bulleted-list"><li style="list-style-type:disc">클래스마다 하나의 출력 뉴런 필요</li></ul><ul id="86a86684-9c89-437e-a4e9-72978d7e9069" class="bulleted-list"><li style="list-style-type:disc">출력층에는 softmax 활성화 함수 사용(모든 예측 확률을 0과 1사이로 만들고 더했을 때 1이 됨)</li></ul><ul id="e587337e-0635-4b4b-8634-6bac327248be" class="bulleted-list"><li style="list-style-type:disc"><span style="border-bottom:0.05em solid">이를 다중 분류라고 부름</span></li></ul><figure id="2de05308-d394-4597-a1bc-b74c4338af95" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%205.png"><img style="width:432px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%205.png"/></a></figure><p id="274e78da-a989-4da1-80d5-32f4b423c125" class="">
</p><p id="42384811-4bda-4bcf-b115-f559b0ead411" class="">loss function: 크로스 엔트로피 손실(=로그 손실) 사용 → 확률 분포 예측</p><figure id="814b3f73-78c9-4ea6-a738-53934783c02f" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%206.png"><img style="width:1804px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%206.png"/></a><figcaption>분류 MLP의 전형적인 구조</figcaption></figure><h2 id="b1422828-8659-4d3d-8b44-3b627edcc491" class="block-color-gray_background">10.2 케라스로 다층 퍼셉트론 구현하기</h2><h3 id="2e92c884-690b-4e72-9207-3f5d267ef311" class="block-color-blue_background">10.2.1 텐서플로 2 설치</h3><p id="c80037ed-54e9-4e09-ab18-84e562b40132" class="">코랩 사용</p><h3 id="12fc1ab8-48ab-4542-a002-74923a0cfd1f" class="block-color-blue_background">10.2.2 시퀀셜 API를 사용하여 이미지 분류기 만들기</h3><p id="567232fe-6438-4db6-9c0f-4c72c9fcc6c1" class="">Fashion MNIST 데이터 사용</p><ul id="955afc00-783e-441a-99b3-7114b4ba8cca" class="bulleted-list"><li style="list-style-type:disc">10개의 클래스</li></ul><ul id="5a846a31-9665-4c8d-90d5-fa1cea74398b" class="bulleted-list"><li style="list-style-type:disc">28 * 28 픽셀 크기의 흑백 이미지 70,000개</li></ul><ul id="6169816b-ad1f-455c-8aea-8ca839757208" class="bulleted-list"><li style="list-style-type:disc">형태가 정확히 같지만 손글씨가 아니라 패션 아이템을 나타내는 이미지</li></ul><p id="83fe28b6-992e-485a-a744-3592a2b90445" class="">
</p><p id="3a9a557c-012a-46c1-a9bc-76e6a2298465" class=""><em><strong>&lt;케라스를 이용하여 데이터 셋 적재하기&gt;</strong></em></p><pre id="04245bb0-12c2-49f2-a698-243c04f9aa92" class="code"><code>fashion_mnist = keras.datasets.fashion_mnist
(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()</code></pre><div id="5ef075ea-3895-435d-9395-701a06fc03be" class="collection-content"><h4 class="collection-title">사이킷런을 사용해 적재하였을 때와 차이가 있음</h4><table class="collection-content"><thead><tr><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesTitle"><path d="M7.73943662,8.6971831 C7.77640845,8.7834507 7.81338028,8.8943662 7.81338028,9.00528169 C7.81338028,9.49823944 7.40669014,9.89260563 6.91373239,9.89260563 C6.53169014,9.89260563 6.19894366,9.64612676 6.08802817,9.30105634 L5.75528169,8.33978873 L2.05809859,8.33978873 L1.72535211,9.30105634 C1.61443662,9.64612676 1.2693662,9.89260563 0.887323944,9.89260563 C0.394366197,9.89260563 0,9.49823944 0,9.00528169 C0,8.8943662 0.0246478873,8.7834507 0.0616197183,8.6971831 L2.46478873,2.48591549 C2.68661972,1.90669014 3.24119718,1.5 3.90669014,1.5 C4.55985915,1.5 5.12676056,1.90669014 5.34859155,2.48591549 L7.73943662,8.6971831 Z M2.60035211,6.82394366 L5.21302817,6.82394366 L3.90669014,3.10211268 L2.60035211,6.82394366 Z M11.3996479,3.70598592 C12.7552817,3.70598592 14,4.24823944 14,5.96126761 L14,9.07922535 C14,9.52288732 13.6549296,9.89260563 13.2112676,9.89260563 C12.8169014,9.89260563 12.471831,9.59683099 12.4225352,9.19014085 C12.028169,9.6584507 11.3257042,9.95422535 10.5492958,9.95422535 C9.60035211,9.95422535 8.47887324,9.31338028 8.47887324,7.98239437 C8.47887324,6.58978873 9.60035211,6.08450704 10.5492958,6.08450704 C11.3380282,6.08450704 12.040493,6.33098592 12.4348592,6.81161972 L12.4348592,5.98591549 C12.4348592,5.38204225 11.9172535,4.98767606 11.1285211,4.98767606 C10.6602113,4.98767606 10.2411972,5.11091549 9.80985915,5.38204225 C9.72359155,5.43133803 9.61267606,5.46830986 9.50176056,5.46830986 C9.18133803,5.46830986 8.91021127,5.1971831 8.91021127,4.86443662 C8.91021127,4.64260563 9.0334507,4.44542254 9.19366197,4.34683099 C9.87147887,3.90316901 10.6232394,3.70598592 11.3996479,3.70598592 Z M11.1778169,8.8943662 C11.6830986,8.8943662 12.1760563,8.72183099 12.4348592,8.37676056 L12.4348592,7.63732394 C12.1760563,7.29225352 11.6830986,7.11971831 11.1778169,7.11971831 C10.5616197,7.11971831 10.056338,7.45246479 10.056338,8.0193662 C10.056338,8.57394366 10.5616197,8.8943662 11.1778169,8.8943662 Z M0.65625,11.125 L13.34375,11.125 C13.7061869,11.125 14,11.4188131 14,11.78125 C14,12.1436869 13.7061869,12.4375 13.34375,12.4375 L0.65625,12.4375 C0.293813133,12.4375 4.43857149e-17,12.1436869 0,11.78125 C-4.43857149e-17,11.4188131 0.293813133,11.125 0.65625,11.125 Z"></path></svg></span>이름</th><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesText"><path d="M7,4.56818 C7,4.29204 6.77614,4.06818 6.5,4.06818 L0.5,4.06818 C0.223858,4.06818 0,4.29204 0,4.56818 L0,5.61364 C0,5.88978 0.223858,6.11364 0.5,6.11364 L6.5,6.11364 C6.77614,6.11364 7,5.88978 7,5.61364 L7,4.56818 Z M0.5,1 C0.223858,1 0,1.223858 0,1.5 L0,2.54545 C0,2.8216 0.223858,3.04545 0.5,3.04545 L12.5,3.04545 C12.7761,3.04545 13,2.8216 13,2.54545 L13,1.5 C13,1.223858 12.7761,1 12.5,1 L0.5,1 Z M0,8.68182 C0,8.95796 0.223858,9.18182 0.5,9.18182 L11.5,9.18182 C11.7761,9.18182 12,8.95796 12,8.68182 L12,7.63636 C12,7.36022 11.7761,7.13636 11.5,7.13636 L0.5,7.13636 C0.223858,7.13636 0,7.36022 0,7.63636 L0,8.68182 Z M0,11.75 C0,12.0261 0.223858,12.25 0.5,12.25 L9.5,12.25 C9.77614,12.25 10,12.0261 10,11.75 L10,10.70455 C10,10.4284 9.77614,10.20455 9.5,10.20455 L0.5,10.20455 C0.223858,10.20455 0,10.4284 0,10.70455 L0,11.75 Z"></path></svg></span>사이킷런</th><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesText"><path d="M7,4.56818 C7,4.29204 6.77614,4.06818 6.5,4.06818 L0.5,4.06818 C0.223858,4.06818 0,4.29204 0,4.56818 L0,5.61364 C0,5.88978 0.223858,6.11364 0.5,6.11364 L6.5,6.11364 C6.77614,6.11364 7,5.88978 7,5.61364 L7,4.56818 Z M0.5,1 C0.223858,1 0,1.223858 0,1.5 L0,2.54545 C0,2.8216 0.223858,3.04545 0.5,3.04545 L12.5,3.04545 C12.7761,3.04545 13,2.8216 13,2.54545 L13,1.5 C13,1.223858 12.7761,1 12.5,1 L0.5,1 Z M0,8.68182 C0,8.95796 0.223858,9.18182 0.5,9.18182 L11.5,9.18182 C11.7761,9.18182 12,8.95796 12,8.68182 L12,7.63636 C12,7.36022 11.7761,7.13636 11.5,7.13636 L0.5,7.13636 C0.223858,7.13636 0,7.36022 0,7.63636 L0,8.68182 Z M0,11.75 C0,12.0261 0.223858,12.25 0.5,12.25 L9.5,12.25 C9.77614,12.25 10,12.0261 10,11.75 L10,10.70455 C10,10.4284 9.77614,10.20455 9.5,10.20455 L0.5,10.20455 C0.223858,10.20455 0,10.4284 0,10.70455 L0,11.75 Z"></path></svg></span>케라스</th></tr></thead><tbody><tr id="8638a2c7-b41a-402d-94e1-ee85ebdbc3f7"><td class="cell-title"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/%E1%84%89%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8F%E1%85%B5%E1%86%BA%E1%84%85%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%89%E1%85%A1%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A2%20%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8C%E1%85%A2%E1%84%92%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%BB%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%84%E1%85%A2%E1%84%8B%E1%85%AA%20%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%80%E1%85%A1%20%E1%84%8B%E1%85%B5%205ef075ea3895435d9395701a06fc03be/%E1%84%8F%E1%85%B3%E1%84%80%E1%85%B5%E1%84%8B%E1%85%AA%20%E1%84%87%E1%85%A2%E1%84%8B%E1%85%A7%E1%86%AF%208638a2c7b41a402d94e1ee85ebdbc3f7.html">크기와 배열</a></td><td class="cell-Ha&lt;|">784 크기/ 1D배열</td><td class="cell-Wa|R">28 * 28 크기의 배열</td></tr><tr id="c014c305-112b-456b-a895-f1a59f97694e"><td class="cell-title"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/%E1%84%89%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8F%E1%85%B5%E1%86%BA%E1%84%85%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%89%E1%85%A1%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A2%20%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8C%E1%85%A2%E1%84%92%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%BB%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%84%E1%85%A2%E1%84%8B%E1%85%AA%20%E1%84%8E%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%80%E1%85%A1%20%E1%84%8B%E1%85%B5%205ef075ea3895435d9395701a06fc03be/%E1%84%91%E1%85%B5%E1%86%A8%E1%84%89%E1%85%A6%E1%86%AF%20%E1%84%80%E1%85%A1%E1%86%BC%E1%84%83%E1%85%A9%20c014c305112b456ba895f1a59f97694e.html">픽셀 강도</a></td><td class="cell-Ha&lt;|">실수(0.0 ~ 255.0)</td><td class="cell-Wa|R">정수(0 ~ 255)</td></tr></tbody></table></div><pre id="bde3a97a-0947-45fb-8d79-fb88a97838de" class="code"><code>#훈련 세트의 크기와 데이터 타입 확인
&gt;&gt;&gt; x_train_full.shape
(60000, 28, 28)
&gt;&gt;&gt; x_train_full.dtype
dtype(&#x27;uint8&#x27;)

#검증 세트 만들기
#입력 특성의 스케일 조정
x_valid, x_train = x_train_full[:5000]/255.0, x_train_full[5000:]/255.0
y_valid, y_train = y_train_full[:5000], y_train_full[5000:]
x_test = x_test/255.0

#클래스 이름 리스트 생성
class_names = [&#x27;T-shirt/top&#x27;, &#x27;Trouser&#x27;, &#x27;Pullover&#x27;, &#x27;Dress&#x27;, &#x27;Coat&#x27;, &#x27;Sandal&#x27;,
               &#x27;Shirt&#x27;, &#x27;Sneaker&#x27;, &#x27;Bag&#x27;, &#x27;Ankle boot&#x27;]

#확인
&gt;&gt;&gt; class_names[y_train[0]]
&#x27;Coat&#x27;</code></pre><p id="4803ca48-b176-476b-8fe2-516d12ad17d3" class="">
</p><p id="b8490796-6931-4866-b9a0-9fa8a6d10f9f" class=""><em><strong>&lt;시퀀셜 API를 사용하여 모델 만들기&gt;</strong></em></p><pre id="26642119-a171-440c-a9f7-879c1a4b95b9" class="code"><code>#신경망 생성
#두 개의 은닉층으로 이루어진 분류용 다층 퍼셉트론
model = keras.models.Sequential() #모델 생성
model.add(keras.layers.Flatten(input_shape=[28,28])) #입력층
model.add(keras.layers.Dense(300, activation=&quot;relu&quot;)) #은닉층
model.add(keras.layers.Dense(100, activation=&quot;relu&quot;)) #은닉층
model.add(keras.layers.Dense(10, activation=&quot;softmax&quot;)) #출력층

&gt;&gt;&gt; model.summary() #첫 번째 은닉층은 파라미터의 갯수를 확인했을 때, 과대적합의 위험 있음을 알 수 있다.
Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
dense (Dense)                (None, 300)               235500    
_________________________________________________________________
dense_1 (Dense)              (None, 100)               30100     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1010      
=================================================================
Total params: 266,610
Trainable params: 266,610
Non-trainable params: 0
_________________________________________________________________

&gt;&gt;&gt; model.layers
[&lt;keras.layers.core.Flatten at 0x7f2954c852d0&gt;,
 &lt;keras.layers.core.Dense at 0x7f2954e2b7d0&gt;,
 &lt;keras.layers.core.Dense at 0x7f2959257650&gt;,
 &lt;keras.layers.core.Dense at 0x7f2954c87650&gt;]

&gt;&gt;&gt;hidden1 = model.layers[1]
&gt;&gt;&gt; hidden1.name
&#x27;dense&#x27;

&gt;&gt;&gt;model.get_layer(&#x27;dense&#x27;) is hidden1
True

#파라미터로의 접근
&gt;&gt;&gt; weights, biases = hidden1.get_weights()
&gt;&gt;&gt; weights
array([[-0.01202889, -0.02520375, -0.02020528, ..., -0.05904793,
         0.0494606 , -0.06317092],
       [-0.05904678,  0.05315712, -0.06610563, ...,  0.06989942,
         0.02853368, -0.00395272],
       [ 0.04747478, -0.06598961,  0.00152043, ...,  0.03865387,
         0.03502854, -0.01272675],
       ...,
       [ 0.029612  , -0.01239874, -0.01016549, ...,  0.02901292,
         0.00269286,  0.02409095],
       [-0.03735555, -0.06553811, -0.04395407, ..., -0.01992206,
        -0.03858028, -0.03149897],
       [-0.01325106,  0.03015194,  0.06456205, ...,  0.03242714,
        -0.05206587,  0.03710809]], dtype=float32)

&gt;&gt;&gt; weights.shape
(784, 300)
&gt;&gt;&gt; biases
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       ... , 0., 0., 0., 0.], dtype=float32)
&gt;&gt;&gt; biases.shape
(300,)</code></pre><p id="2937d07a-4d5c-42ae-84a3-e1e87057c8b3" class="">Dense 층은 연결 가중치를 무작위로 초기화, 편향은 0으로 초기화 → for. 대칭성 붕괴</p><p id="ba4e1680-a52a-4012-ad3e-c2cbfbcf69bf" class="">
</p><p id="1712c2f1-6fd0-4c3f-8d7b-b4cefc1ec6cb" class=""><em><strong>&lt;모델 컴파일&gt;</strong></em></p><pre id="d4b1dd03-68f0-4e20-8421-c5a9d5093d57" class="code"><code>model.compile(loss=&#x27;sparse_categorical_crossentropy&#x27;,
              optimizer=&#x27;sgd&#x27;,
              metrics=[&#x27;accuracy&#x27;])</code></pre><p id="c89c4096-74f9-4b85-befc-edbc2b2eec9e" class="">&#x27;sparse_categorical_crossentropy&#x27; 손실 사용</p><ul id="afc8db12-86eb-4c68-8f2e-ecb588407d3e" class="bulleted-list"><li style="list-style-type:disc">레이블이 정수 하나(샘플마다 타깃 클래스 인덱스 하나 존재)</li></ul><ul id="e7bd23f4-0ed8-4d77-acc1-c2b2c03ecd66" class="bulleted-list"><li style="list-style-type:disc">클래스가 배타적</li></ul><p id="041a16a3-b2b8-476d-82b9-cbd4c3f9562a" class="">☑️ 샘플마다 클래스별 타깃 확률을 가지고 있다면, &#x27;categorical_crossentropy&#x27; 손실 사용</p><p id="54d44193-74fb-4fec-a62c-9e1e9b594ac6" class="">
</p><p id="d4828cc8-127c-4122-af06-e56b4b86f48b" class="">옵티마이저 &#x27;sgd&#x27;</p><ul id="21846b7e-3e41-41af-b056-135323da643d" class="bulleted-list"><li style="list-style-type:disc">기본 확률적 경사 하강법을 사용하여 모델을 훈련한다 라는 의미</li></ul><ul id="58ecca27-728c-4e2a-bff5-bb57c707a66e" class="bulleted-list"><li style="list-style-type:disc">= 역전파 알고리즘 수행</li></ul><ul id="5b1c836b-1c05-4969-af03-6dd829efae41" class="bulleted-list"><li style="list-style-type:disc">학습률 튜닝이 중요(디폴트: lr = 0.01)</li></ul><p id="3aebf247-c8c0-48b9-bc83-02ff9e24f2ea" class="">
</p><p id="79a91351-2e2a-4f63-b947-04ed96f9b97d" class="">정확도 측정</p><ul id="3083132f-19c1-4f7e-bf0d-7dbe8c8d3c00" class="bulleted-list"><li style="list-style-type:disc">accuracy</li></ul><p id="9a9e8d95-fe82-4da8-9c7a-199999976cf5" class="">
</p><p id="952316f4-cc88-4cf2-b878-8128a7d3a7a3" class=""><em><strong>&lt;모델 훈련과 평가&gt;</strong></em></p><pre id="5cc402a8-d2b7-4757-b9e8-9406205f232c" class="code"><code>&gt;&gt;&gt; history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_valid))
Epoch 1/30
1719/1719 [==============================] - 8s 3ms/step - loss: 0.7260 - accuracy: 0.7606 - val_loss: 0.5170 - val_accuracy: 0.8256
Epoch 2/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.4950 - accuracy: 0.8278 - val_loss: 0.4490 - val_accuracy: 0.8506
.
.
.
Epoch 29/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.2309 - accuracy: 0.9166 - val_loss: 0.2953 - val_accuracy: 0.8920
Epoch 30/30
1719/1719 [==============================] - 6s 3ms/step - loss: 0.2267 - accuracy: 0.9197 - val_loss: 0.3034 - val_accuracy: 0.8908</code></pre><p id="2276b55b-e7af-4f5c-beb8-6f08cf5eceb9" class="">훈련 세트의 성능 &gt;&gt;&gt;&gt; 검증 세트 성능 → 과대적합 or 버그 가능성 있음</p><p id="d0d4a74c-0148-4f59-8052-062cbf934b71" class="">에포크가 지날 수록 훈련 손실 감소</p><p id="2685ccbe-391f-43ff-866f-5833e431faf5" class="">
</p><p id="121d0058-7731-44a2-9123-509aa66843ea" class=""><span style="border-bottom:0.05em solid">훈련 세트 편중</span> → 클래스별 가중치 부여: class_weight 매개변수 지정</p><p id="dc017c4f-47b0-4d5e-a91d-8bb10d03aa1a" class="">샘플별 가중치 부여: sample_weight 매개변수 지정</p><p id="847d9578-a3ff-4b72-9691-302cb95a105a" class="">#둘 다 지정됐을 경우, 두 값을 곱하여 사용</p><p id="6077021f-3851-4f60-acbe-b69feb3e9798" class="">
</p><pre id="4c4e401b-9b6b-44af-be8d-199171871a43" class="code"><code>import pandas as pd
import matplotlib.pyplot as plt

pd.DataFrame(history.history).plot(figsize=(8,5))
plt.grid(True)
plt.gca().set_ylim(0.1) #수직축의 범위를 0과1 사이로 설정
plt.show();</code></pre><figure id="9e7dc70a-c4b5-4fd0-b2dc-b5d0dfeb27b2" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%207.png"><img style="width:483px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%207.png"/></a><figcaption>학습 곡선(learning curve)</figcaption></figure><ul id="4024103d-e6e1-4e0e-9d62-05b76ae05cdb" class="bulleted-list"><li style="list-style-type:disc">각 정확도 꾸준히 상승</li></ul><ul id="51b2643a-3b52-4bb9-8248-5f4b8cbc891f" class="bulleted-list"><li style="list-style-type:disc">각 손실은 모두 감소</li></ul><ul id="b2214714-5410-41b6-8fb5-cc129efc6788" class="bulleted-list"><li style="list-style-type:disc">훈련 곡선과 검증 곡선이 가까움 → 과대적합 X</li></ul><ul id="7916c975-f309-4bd5-bb8e-87c1b6d82e24" class="bulleted-list"><li style="list-style-type:disc">훈련 손실: 에포크가 진행되는 동안 계산 // 검증 손실: 에포크가 끝난 후 계산 
→ 훈련 곡선은 에포크의 절반 만큼 왼쪽으로 이동 
→ 두 곡선 거의 일치 ! </li></ul><p id="261b6d34-6954-4ea8-80c7-5de7e7d9db4e" class="">
</p><p id="fd278691-541d-4dfe-a7bc-d5eddc5b16b6" class="">모델이 만족스럽지 않다면, 처음으로 돌아가 <strong><mark class="highlight-blue">하이퍼파라미터 튜닝</mark></strong></p><ol type="1" id="16bdd86e-2c2f-4c55-85d0-0df3eafc5d55" class="numbered-list" start="1"><li>학습률 확인</li></ol><ol type="1" id="e6b4490c-607c-4e19-811b-f252ff259098" class="numbered-list" start="2"><li>다른 옵티마이저</li></ol><ol type="1" id="397132d7-a5e5-4260-b621-5b9a3c832b9e" class="numbered-list" start="3"><li>층 개수, 층에 있는 뉴런 개수, 은닌층이 사용하는 활성화 함수 등</li></ol><ol type="1" id="4297cab0-ffe1-4e8b-b78d-c9840873ea8b" class="numbered-list" start="4"><li>배치 크기(fit( ) 메서드 → default: batch_size = 32)</li></ol><p id="f5e40d58-b446-4a5e-bd54-5aeea1e8c786" class="">
</p><p id="7236585e-bf1c-429f-83d0-98ad26e85706" class="">모델이 만족스럽다면, 배포 전 모델 평가(일반화 오차 추정)</p><pre id="f0b6e66f-d69c-463a-a9b4-907a2cc7bb89" class="code"><code>#evaluate( ) 메서드 사용
&gt;&gt;&gt; model.evaluate(x_test, y_test)
313/313 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8824
[0.337948739528656, 0.8823999762535095]</code></pre><ul id="babb05ce-c2e6-457e-87ab-8f029ffa9226" class="bulleted-list"><li style="list-style-type:disc">일반적으로 검증 세트보다 테스트 세트에서의 성능이 낮음</li></ul><ul id="bdc786e1-262b-40eb-96b0-9c737d00fa30" class="bulleted-list"><li style="list-style-type:disc">하이퍼파라미터 튜닝 → 검증 세트에서 이루어졌기 때문</li></ul><p id="6f4ec215-6b39-473d-9cf6-59b034e67ce6" class="">
</p><p id="41cac1ee-7616-4c83-a6eb-e97e5b7632e2" class=""><em><strong>&lt;모델을 사용해 예측을 만들기&gt;</strong></em></p><pre id="43803aa3-edfd-4c50-8145-2f1491b3d2a4" class="code"><code>#predict()메서드 사용
&gt;&gt;&gt; x_new = x_test[:3]
&gt;&gt;&gt; y_proba = model.predict(x_new)
&gt;&gt;&gt; y_proba.round(2)
array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.03, 0.  , 0.95],
       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],
       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],
      dtype=float32)

#가장 높은 확률을 가진 클래스
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; y_pred = np.argmax(y_proba, axis=1) #교재에서 사용한 predict_classes는 21년 1월 1일 후로 삭제됨.
&gt;&gt;&gt; y_pred
array([9, 2, 1])

&gt;&gt;&gt; np.array(class_names)[y_pred]
array([&#x27;Ankle boot&#x27;, &#x27;Pullover&#x27;, &#x27;Trouser&#x27;], dtype=&#x27;&lt;U11&#x27;)

#올바르게 분류
&gt;&gt;&gt; y_new = y_test[:3]
&gt;&gt;&gt; y_new
array([9, 2, 1], dtype=uint8)</code></pre><h3 id="5da42672-dd9d-48db-97f7-30d37bb58da0" class="block-color-blue_background">10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기</h3><p id="6f9a45fd-90e7-454d-8130-a7a97bdbd031" class="">
</p><pre id="b0b9a266-bea5-4dd4-963f-2431b3128fd6" class="code"><code>from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

housing = fetch_california_housing()

x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)
x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_valid = scaler.transform(x_valid)
x_test = scaler.transform(x_test)</code></pre><ul id="189d9eff-4e46-4405-b50b-57659497a901" class="bulleted-list"><li style="list-style-type:disc">분류에서 했던 방법과 비슷</li></ul><ul id="01638c70-3bce-4613-acdb-cc0bbeb9962c" class="bulleted-list"><li style="list-style-type:disc">출력층이 활성화 함수가 없는 하나의 뉴런을 가짐(✔️ 하나의 값 예측)</li></ul><ul id="440317af-efa7-435f-82a2-59b87710e94a" class="bulleted-list"><li style="list-style-type:disc">손실 함수: 평균 제곱 오차 사용</li></ul><ul id="9e920d92-b2ce-407f-a496-4eced4d55e69" class="bulleted-list"><li style="list-style-type:disc">사용한 데이터는 잡음 多 → 과대적합을 막고자 뉴런 수가 적은 은닉층 하나만 사용</li></ul><p id="f0b82278-dd0c-48ba-b686-44fc0e4a18b1" class="">
</p><pre id="67ea9f32-ada3-4221-a759-b1005e40cddf" class="code"><code>&gt;&gt;&gt; model = keras.models.Sequential([keras.layers.Dense(30, activation=&quot;relu&quot;, input_shape = x_train.shape[1:]),
                                 keras.layers.Dense(1)])

&gt;&gt;&gt; model.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=&#x27;sgd&#x27;)

&gt;&gt;&gt; history = model.fit(x_train, y_train, epochs=20, validation_data=(x_valid, y_valid))
&gt;&gt;&gt; mse_test = model.evaluate(x_test, y_test)

&gt;&gt;&gt; x_new = x_test[:3]
&gt;&gt;&gt; y_pred = model.predict(x_new)

Epoch 1/20
363/363 [==============================] - 2s 4ms/step - loss: 1.0201 - val_loss: 0.5163
Epoch 2/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4473 - val_loss: 2.5473
.
.
.
Epoch 19/20
363/363 [==============================] - 1s 3ms/step - loss: 0.3458 - val_loss: 0.4143
Epoch 20/20
363/363 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.3647
162/162 [==============================] - 0s 2ms/step - loss: 0.3581</code></pre><h3 id="6369e74c-6a45-48f9-b428-7a7f12bc3f59" class="block-color-blue_background">10.2.4 함수형 API를 사용해 복잡한 모델 만들기</h3><p id="8651caa9-aca4-43bb-a4a2-8753dd2b0e89" class="">순차적이지 않은 신경망: <mark class="highlight-blue"><strong>와이드 &amp; 딥 신경망</strong></mark></p><p id="47aa57ef-8ae5-4334-96f3-c0af65194062" class="">
</p><figure id="b1eef1ad-1650-4b24-8a93-57f75cc4dbf2" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%208.png"><img style="width:432px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%208.png"/></a></figure><ul id="5a6ef9ff-cbc9-41fb-ab6d-a317215acd87" class="bulleted-list"><li style="list-style-type:disc">입력의 일부 또는 전체가 출력층에 바로 연결</li></ul><ul id="bdea431f-9c3f-4272-b272-1b79bd4fcb8d" class="bulleted-list"><li style="list-style-type:disc">복잡한 패턴(깊게 쌓은 층을 사용한) &amp; 간단한 규칙(짧은 경로를 사용한)을 모두 학습할 수 있음</li></ul><pre id="89e6595e-688c-4827-846f-2d1ea24151c9" class="code"><code>input_ = keras.layers.Input(shape=x_train.shape[1:]) #입력층
hidden1 = keras.layers.Dense(30, activation=&#x27;relu&#x27;)(input_) #은닉층 1
hidden2 = keras.layers.Dense(30, activation=&#x27;relu&#x27;)(hidden1) #은닉층 2
concat = keras.layers.Concatenate()([input_, hidden2]) #층 연결
output = keras.layers.Dense(1)(concat) #출력층
model = keras.Model(inputs = [input_], outputs = [output]) #모델 생성</code></pre><figure id="16e8bf78-c16f-4f95-b437-f3a8171befbe" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%209.png"><img style="width:288px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%209.png"/></a></figure><pre id="99d606ab-51bd-462d-aab5-700ef01f0f06" class="code"><code>#일부 특성은 짧은 경로로, 다른 특성은 깊은 경로로
#여러 입력을 사용
input_A = keras.layers.Input(shape=[5], name=&#x27;wide_input&#x27;)
input_B = keras.layers.Input(shape=[6], name=&#x27;deep_input&#x27;)
hidden1 = keras.layers.Dense(30, activation=&#x27;relu&#x27;)(input_B)
hidden2 = keras.layers.Dense(30, activation=&#x27;relu&#x27;)(hidden1)
concat = keras.layers.Concatenate()([input_A, hidden2])
output = keras.layers.Dense(1, name=&#x27;output&#x27;)(concat)
model = keras.Model(inputs = [input_A, input_B], outputs = [output])</code></pre><ul id="668c8b1d-e8c4-4799-a43c-5623c716196f" class="bulleted-list"><li style="list-style-type:disc">fit( )을 호출할 때 x_train만 전달하는 것이 아님 → (x_train_A, x_train_B)로 전달</li></ul><ul id="27a93cd4-a189-4f16-bf43-7baa282756a2" class="bulleted-list"><li style="list-style-type:disc">evaluate( ), predict( )도 마찬가지임</li></ul><p id="dbf8008f-09a8-40c5-9660-06f41efd8108" class="">
</p><pre id="f3522d74-3128-411a-9bc9-65734c3df5d9" class="code"><code>&gt;&gt;&gt; model.compile(loss=&#x27;mse&#x27;, optimizer=keras.optimizers.SGD(learning_rate=1e-3))

&gt;&gt;&gt; x_train_A, x_train_B = x_train[:,:5], x_train[:,2:]
&gt;&gt;&gt; x_valid_A, x_valid_B = x_valid[:,:5], x_valid[:,2:]
&gt;&gt;&gt; x_test_A, x_test_B = x_test[:,:5], x_test[:,2:]
&gt;&gt;&gt; x_new_A, x_new_B = x_test_A[:3], x_test_B[:3]

&gt;&gt;&gt; history = model.fit((x_train_A, x_train_B), y_train, epochs=20, 
                        validation_data=((x_valid_A, x_valid_B), y_valid))
&gt;&gt;&gt; mse_test = model.evaluate((x_test_A, x_test_B), y_test)
&gt;&gt;&gt; y_pred = model.predict((x_new_A, x_new_B))

Epoch 1/20
363/363 [==============================] - 2s 3ms/step - loss: 2.1259 - val_loss: 0.9569
Epoch 2/20
363/363 [==============================] - 1s 3ms/step - loss: 0.8205 - val_loss: 0.7564
Epoch 3/20
363/363 [==============================] - 1s 3ms/step - loss: 0.7030 - val_loss: 0.6858
.
.
.
Epoch 19/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4768 - val_loss: 0.4674
Epoch 20/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4739 - val_loss: 0.4675
162/162 [==============================] - 0s 2ms/step - loss: 0.4774</code></pre><p id="26ee30be-e1d9-43a8-bb81-29029881e32f" class="">여러 개의 출력이 필요한 경우</p><ul id="76002b0c-946a-46ea-a141-a9ed5be07416" class="bulleted-list"><li style="list-style-type:disc">여러 출력이 필요한 작업(ex. 회귀 작업과 분류 작업을 함께하는 경우)</li></ul><ul id="83d8f539-d74e-445e-81fa-c5a51eceefc6" class="bulleted-list"><li style="list-style-type:disc">동일한 데이터에서 독립적인 여러 작업을 수행할 때
(ex. 다중분류작업 → 사람의 표정 분류 후 안경 착용 유무 분류)</li></ul><ul id="88f5b6ca-48b2-4437-8512-125ccdd3eb9e" class="bulleted-list"><li style="list-style-type:disc">규제 기법으로 사용<figure id="8bdcaf46-4963-48ac-a398-87e4401d52ba" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%2010.png"><img style="width:384px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%2010.png"/></a></figure><pre id="edaa8022-20dd-4302-a1c1-fd423a9e2e77" class="code"><code>#출력층까지는 이전과 동일
input_A = keras.layers.Input(shape=[5], name=&#x27;wide_input&#x27;)
input_B = keras.layers.Input(shape=[6], name=&#x27;deep_input&#x27;)
hidden1 = keras.layers.Dense(30, activation=&#x27;relu&#x27;)(input_B)
hidden2 = keras.layers.Dense(30, activation=&#x27;relu&#x27;)(hidden1)
concat = keras.layers.Concatenate()([input_A, hidden2])

output = keras.layers.Dense(1, name=&#x27;main_output&#x27;)(concat)
aux_output = keras.layers.Dense(1, name=&#x27;aux_output&#x27;)(hidden2)
model = keras.Model(inputs = [input_A, input_B], outputs = [output, aux_output])</code></pre></li></ul><p id="d472978a-3a8c-4cd8-bbfc-ecb48bfee2a0" class="">
</p><p id="58632df1-1d2a-460e-b3f1-ec61ea8db602" class="">각 출력은 자신만의 손실 함수 필요 → 컴파일할 때 소실의 리스트 전달</p><p id="dd120621-0379-431b-b6ec-842f7b5ca5f9" class="">나열된 손실의 합 ⇒ 최종 손실</p><p id="424d175c-5794-4924-84fb-c76fddad0488" class="">주 출력의 손실에 더 많은 가중치 부여</p><pre id="b7f203bd-5351-4c22-b0de-087ccf8974cd" class="code"><code>model.compile(loss=[&#x27;mse&#x27;, &#x27;mse&#x27;], loss_weights=[0.9, 0.1], optimizer=&#x27;sgd&#x27;)</code></pre><p id="f140e2aa-f09f-48f3-a5b8-3c9ddcf59f32" class="">
</p><p id="82cb39f1-3b3d-4854-ba85-6c5883f0f84c" class="">각 출력에 대한 레이블 제공</p><pre id="6db01d24-731a-4540-bfc2-67032f639d90" class="code"><code>&gt;&gt;&gt; history = model.fit([x_train_A, x_train_B], [y_train, y_train],
                        epochs=20, validation_data=([x_valid_A, x_valid_B], [y_valid, y_valid]))
Epoch 1/20
363/363 [==============================] - 3s 6ms/step - loss: 0.9540 - main_output_loss: 0.8599 - aux_output_loss: 1.8010 - val_loss: 0.6034 - val_main_output_loss: 0.5496 - val_aux_output_loss: 1.0883
Epoch 2/20
363/363 [==============================] - 2s 5ms/step - loss: 0.5891 - main_output_loss: 0.5367 - aux_output_loss: 1.0601 - val_loss: 0.4754 - val_main_output_loss: 0.4309 - val_aux_output_loss: 0.8756
Epoch 3/20
.
.
.
Epoch 19/20
363/363 [==============================] - 2s 5ms/step - loss: 0.4053 - main_output_loss: 0.3933 - aux_output_loss: 0.5138 - val_loss: 0.3423 - val_main_output_loss: 0.3282 - val_aux_output_loss: 0.4690
Epoch 20/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3823 - main_output_loss: 0.3682 - aux_output_loss: 0.5087 - val_loss: 0.3476 - val_main_output_loss: 0.3354 - val_aux_output_loss: 0.4568</code></pre><p id="260583a3-6045-434d-9b93-301142f344b0" class="">
</p><p id="481c2eba-34bd-43ad-a2f8-f5ab7b1d469f" class="">모델 평가 → 개별 손실과 총 손실 반환</p><pre id="ff0c08ec-56cf-4669-b8fc-03525d338ff2" class="code"><code>&gt;&gt;&gt; total_loss, main_loss, aux_loss = model.evaluate(
        [x_test_A, x_test_B], [y_test, y_test])

162/162 [==============================] - 0s 3ms/step - loss: 0.4059 - main_output_loss: 0.3958 - aux_output_loss: 0.4973</code></pre><p id="e184583d-a693-4c04-9385-6c5198c7fe7b" class="">
</p><p id="724cde19-54f7-4f4c-985f-6809956f7267" class="">각 출력에 대한 예측 반환</p><pre id="f0bdfb24-7271-4d7b-9b0f-e6efd1dd9a18" class="code"><code>y_pred_main, y_pred_aux = model.predict([x_new_A, x_new_B])</code></pre><h3 id="05fde0f5-0198-4f39-b5a3-17fc577300f3" class="block-color-blue_background">10.2.5 서브클래싱 API로 동적 모델 만들기</h3><p id="bddcde6b-4726-4aaf-906f-85b82e22e6f0" class="">시퀀셜 API, 함수형API: 선언적</p><p id="c8919644-d806-47f4-8e56-6ed4b5f074a5" class="">사용할 층과 연결 방식 먼저 정의 → 모델에 데이터 주입 → 훈련 및 추론</p><ul id="1f870cec-c257-46f6-a6d9-bf4994d71a07" class="bulleted-list"><li style="list-style-type:disc">모델의 저장, 복사, 공유가 쉬움</li></ul><ul id="c23162be-74c3-4bab-a6a1-00db1871550d" class="bulleted-list"><li style="list-style-type:disc">모델의 구조를 출력, 분석하기 좋음</li></ul><ul id="a64a3377-fdc3-4261-8bec-731e403f44fe" class="bulleted-list"><li style="list-style-type:disc">에러를 일찍 발견할 수 있음</li></ul><ul id="7c33142c-dd3d-4ebe-8e96-c906f9f08ea7" class="bulleted-list"><li style="list-style-type:disc">디버깅도 쉬움</li></ul><p id="7b022e60-e949-455d-9420-77ef18f2005b" class=""><span style="border-bottom:0.05em solid">동적인 구조</span>가 필요할 때는 정적이라는 것이 단점</p><p id="0c8fe61f-754b-4b4d-8c57-7464f9c4db33" class="">⇒ 명령형 프로그래밍 스타일 - <span style="border-bottom:0.05em solid">서브클래싱 API ‼️</span></p><p id="addc17de-927d-45d1-b721-42efd42f1a8c" class="">
</p><pre id="e5651e38-9839-4ef0-a2af-7f8bcf0e5a7e" class="code"><code>class WideAndDeepModel(keras.Model):
    def __init__(self, units=30, activation=&#x27;relu&#x27;, **kwargs):
        super().__init__(**kwargs)
        self.hidden1 = keras.layers.Dense(units, activation=activation)        
        self.hidden2 = keras.layers.Dense(units, activation=activation)
        self.main_output = keras.layers.Dense(1)
        self.aux_output = keras.layers.Dense(1)

    def call(self, inputs):
        input_A, input_B = inputs
        hidden1 = self.hidden1(input_B)
        hidden2 = self.hidden2(hidden1)
        concat = keras.layers.concatenate([input_A, hidden2])
        main_output = self.main_output(concat)
        aux_output = self.aux_output(hidden2)
        return main_output, aux_output

model = WideAndDeepModel()</code></pre><p id="25f16d97-c17c-44dd-a38a-dd27c23ddb12" class="">→ 높은 유연성을 필요로 하지 않는다면 시퀀셜 API과 함수형API를 사용하는 것이 좋음</p><h3 id="031af980-db17-4b09-898a-2aa83cbfe1cf" class="block-color-blue_background">10.2.6 모델 저장과 복원</h3><pre id="e120b909-a75f-4a8c-b4e0-eb53704f304d" class="code"><code>#모델 저장
model = keras.models.Sequential([...])
model.compile([...])
model.fit([...])
model.save(&#x27;my_keras_model.h5&#x27;)

#모델 불러오기
model = keras.models.load_model(&#x27;my_keras_model.h5&#x27;)</code></pre><p id="26aae2d0-10e7-4674-aab7-77d281824948" class="">
</p><h3 id="30ae6cb0-f1e3-46bd-8dfe-47f5b73f6bc8" class="block-color-blue_background">10.2.7 콜백 사용하기</h3><p id="8c174ea3-d82d-442c-b8ee-5e9257fe40de" class="">대규모의 데이터 셋 학습 시 정보를 잃지 않으려면, 훈련 도중 일정 간격으로 체크포인트 저장</p><p id="0ce8706b-dfa2-45ec-b381-0939d01981e3" class="">기본적으로 매 에포크 의 끝에서 호출</p><pre id="76942216-b17a-405c-be19-d4476a9303f4" class="code"><code>[...] #모델을 만들고 컴파일 하기
checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;my_keras_model.h5&#x27;)
history = model.fit(x_train, y_train, epochs=10, callbacks=[checkpoint_cb])

#조기 종료 구현1
#최상의 검증 세트 점수에서만 모델 저장
checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;my_keras_model.h5&#x27;, 
                                                save_best_only = True)
history = model.fit(x_train, y_train, epochs=10, 
                    validation_data=(x_valid, y_valid),
                    callbacks=[checkpoint_cb])
model = keras.models.load_model(&#x27;my_keras_model.h5&#x27;) #최상의 모델로 복원

#조기 종료 구현2
early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,
                                                  restore_best_weights=True)
history = model.fit(x_train, y_train, epochs=10, #모델이 향상되지 않으면 자동으로 훈련이 멈추기 때문에 크게 지정해도 됨
                    validation_data=(x_valid, y_valid),
                    callbacks=[checkpoint_cb])
model = keras.models.load_model(&#x27;my_keras_model.h5&#x27;)

#더 많은 제어 - 사용자 정의 콜백
class PrintValTrainRatioCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs):
        print(&#x27;\nval/train: {:.2f}&#x27;.format(logs[&#x27;val_loss&#x27;] / logs[&#x27;loss&#x27;]))</code></pre><h3 id="861db455-fdeb-42e5-9cb7-67518b80f493" class="block-color-blue_background">10.2.8 텐서보드를 사용해 시각화하기</h3><p id="1715fad8-9f3e-46fb-b84a-7a3eeeec1527" class="">이벤트 파일(이진 로그 파일) - 시각화하려는 데이터 출력</p><p id="da998ae3-00db-44d8-8bf5-ee49404a2e99" class="">각각의 이진 데이터 레코드: 서머리(summary)</p><pre id="fd5c64b2-b6f1-43c4-b4a0-456920f07e21" class="code"><code>#사용할 루트 로그 디렉토리 정의
import os
root_logdir = os.path.join(os.curdir, &#x27;my_logs&#x27;)

#실행할 때마다 다른 서브디렉토리 경로 생성
def get_run_logdir():
    import time
    run_id = time.strftime(&#x27;run_%Y_%m_%d-%H_%M_%S&#x27;)
    return os.path.join(root_logdir, run_id)

run_logdir = get_run_logdir()</code></pre><pre id="76a0253a-807b-4e46-9e9b-3932e3a8e8c0" class="code"><code>#모델 구성과 컴파일
model = keras.models.Sequential([keras.layers.Dense(30, activation=&quot;relu&quot;,
                                                    input_shape = x_train.shape[1:]),keras.layers.Dense(1)])

model.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=&#x27;sgd&#x27;) 

tensorboard_cb = keras.callbacks.TensorBoard(run_logdir) #텐서보드 콜백이 로그 디렉토리 생성
history = model.fit(x_train, y_train, epochs=30, 
                    validation_data=(x_valid, y_valid),
                    callbacks=[tensorboard_cb])</code></pre><figure id="ed4e54a1-24d3-4602-a00d-600d337dfb09" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%2011.png"><img style="width:288px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%2011.png"/></a><figcaption>실행마다 하나의 디렉토리 생성</figcaption></figure><pre id="f048791d-1047-4433-a143-52c889e9ac34" class="code"><code>#텐서보드 서버 시작
%load_ext tensorboard
%tensorboard --logdir=./my_logs --port=6006</code></pre><figure id="abaad5ff-ca53-4988-b2fc-ced31fbdc87e" class="image"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%2012.png"><img style="width:2632px" src="Week1%208e3cc69f4e08483293a27c2b56187454/Untitled%2012.png"/></a></figure><h2 id="7064e125-56f4-4e3c-892b-f82cd4f8bfe4" class="block-color-gray_background">10.3 신경망 하이퍼파라미터 튜닝하기</h2><p id="f65960b3-5535-43d3-b7b3-c3a740e83eb1" class="">유연성 - 최적의 하이퍼파라미터 찾기</p><ul id="2fac1b95-fb1b-4fdd-8cc4-06d3a00dc888" class="bulleted-list"><li style="list-style-type:disc">많은 조합을 시도해보고 어떤 것이 검증 세트에서 가장 좋은 점수를 내는지 확인<pre id="36f1a5c7-5c44-435e-a238-e545441d9009" class="code"><code>#케라스 모델을 사이킷런 추정기처럼 보이도록
#케라스 모델 생성 및 컴파일 함수 생성
def bulid_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):
    model = keras.models.Sequential()
    model.add(keras.layers.InputLayer(input_shape=input_shape))
    for layer in range(n_hidden):
        model.add(keras.layers.Dense(n_neurons, activation=&#x27;relu&#x27;))
    model.add(keras.layers.Dense(1))
    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)
    model.compile(loss=&#x27;mse&#x27;, optimizer=optimizer)
    return model

#케라스 모델을 감싸는 레퍼 생성
keras_reg = keras.wrappers.scikit_learn.KerasRegressor(bulid_model)

#케라스 모델을 일반 사이킷런 회귀 추정기처럼 사용 가능
keras_reg.fit(x_train, y_train, epochs=100, 
              validation_data=(x_valid, y_valid),
              callbacks=[keras.callbacks.EarlyStopping(patience=10)])
mse_test = keras_reg.score(x_test, y_test)
y_pred = keras_reg.predict(x_new)

#랜덤 탐색 (1시간 걸림...)
from scipy.stats import reciprocal
from sklearn.model_selection import RandomizedSearchCV

params_distribs = {
    &#x27;n_hidden&#x27;: [0,1,2,3],
    &#x27;n_neurons&#x27;: np.arange(1,100),
    &#x27;learning_rate&#x27;: reciprocal(3e-4, 3e-2)
}

rnd_search_cv = RandomizedSearchCV(keras_reg, params_distribs, n_iter=10, cv=3)
rnd_search_cv.fit(x_train, y_train, epochs=100,
                  validation_data=(x_valid, y_valid),
                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])

#최상의 하이퍼파라미터와 훈련된 케라스 모델
&gt;&gt;&gt; rnd_search_cv.best_params_
{&#x27;learning_rate&#x27;: 0.02626563927521171, &#x27;n_hidden&#x27;: 2, &#x27;n_neurons&#x27;: 91}

&gt;&gt;&gt; rnd_search_cv.best_score_
-0.2984093427658081

&gt;&gt;&gt; model = rnd_search_cv.best_estimator_.model #모델 생성</code></pre></li></ul><ul id="dbb4a99f-b117-4744-b6a7-0e8567ba0974" class="bulleted-list"><li style="list-style-type:disc">랜덤 탐색을 이용하는 것은 어렵지 않지만 데이터 셋이 커졌을 때 효율적인 방법은 아님<del>(공간의 제약)</del></li></ul><ul id="73b2358f-fc3f-4044-844c-32aeda95b286" class="bulleted-list"><li style="list-style-type:disc">수동으로 보조하여 문제 완화 가능(범위를 점점 줄여서 탐색하는 방식)
→ 이것도 좋은 방식은 아님</li></ul><ul id="1d7714c9-201e-4ed3-9526-107eb8145089" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-orange_background"><strong>효율적인 공간 탐색 기법
</strong></mark>- 탐색 지역이 좋다고 판명될 때, 더 탐색을 수행하는 것
<mark class="highlight-gray">- Hyperpot
- Hyperas, kopt, Talos
- Keras Tuner
- Scikit - Optimize(skopt)
- Spearmint
- Hyperband
- Sklearn - Deap</mark></li></ul><h3 id="21fdc8e9-f503-472b-bb64-3fcec162534c" class="block-color-blue_background">10.3.1 은닉층 개수</h3><p id="b922544c-6834-4ea4-8bdd-b155a817a45f" class="">뉴런 수만 무한하다면 은닉층 하나로 어떤 함수도 근사할 수 있음</p><p id="ded91eee-9ca8-4f74-9b43-297b7eb13109" class="">하지만, 복잡한 문제에서는 심층 신경망의 파라미터 효율성이 훨씬 좋음</p><p id="637e6b52-cb00-4df2-b088-badacb3af4a2" class=""><mark class="highlight-blue"><strong>계층 구조</strong></mark> → 입력층 &gt; 아래쪽 은닉층 &gt; 중간 은닉층 &gt; 위쪽 은닉층 &gt;출력층
                                  저수준의 구조 모델링
                                                           저수준 구조 연결 중간 수준 구조 모델링
                                                                                          중간 수준 구조 연결 고수준 구조 모델링</p><ul id="5c2ceda9-9b46-40d7-84e9-1e2dbf670738" class="bulleted-list"><li style="list-style-type:disc">학습 시간 단축</li></ul><ul id="83987fb2-bcb3-487b-b04a-0ea3246cb5e1" class="bulleted-list"><li style="list-style-type:disc">새로운 데이터에 일반화되는 능력 향상
새로운 신경망에서 처음 몇 개 층의 가중치와 편향을 첫 번째 신경망의 층에 있는 가중치와 편향값으로 초기화
저수준 구조를 학습할 필요 X → 고수준 구조만 학습‼️
⇒ <mark class="highlight-red"><strong>전이학습</strong></mark></li></ul><p id="8fae543b-46bd-471c-9e0a-39f789bcbce6" class="">
</p><h3 id="790b0627-bc1c-428f-b0f4-0416887eedfa" class="block-color-blue_background">10.3.2 은닉층의 뉴런 개수</h3><p id="85a40831-33aa-4a5e-a629-678a5cf0c3c2" class="">과거에는 깔때기 구성 (은닉층마다 300개 → 200개 → 100개)</p><p id="34e1e6ab-1575-433c-9360-6b695a3865ae" class="">현재는 모든 은닉층에 같은 크기 사용 </p><p id="9ea495c5-0442-4726-b0dc-cd1f50af1833" class="">튜닝할 하이퍼파라미터 → 층 마다 한 개씩 X // 전체 통틀어 한 개</p><p id="c7d9aa73-fb67-4d70-abae-0dca2cdf1a9b" class="">⇒ <span style="border-bottom:0.05em solid">데이터 셋에 따라 다르지만 첫 번째 은닉층을 크게하는 것이 도움 됨</span></p><p id="588cbf4a-fd0f-47e8-81e5-41f87a4cb82f" class="">
</p><p id="2e1945f7-672e-46e8-b66d-d2605f16f650" class="">과대적합을 사전에 방지 X</p><p id="15d59889-3a67-4a1c-b907-3970e7b3e3a5" class="">필요한 것보다 더 많은 층과 뉴런을 가진 모델 선택 → 조기 종료 or 규제 기법 사용</p><p id="2c40dfb2-d67c-4b85-a0ee-16f4f37613ed" class="">⇒ &#x27;스트레치 팬츠&#x27; 방식</p><ul id="6bf4e6e0-ec48-461e-95a9-fbb99feabe63" class="bulleted-list"><li style="list-style-type:disc">병목층을 피할 수 있음</li></ul><ul id="525437af-6c21-4692-a3aa-f43f8c64417b" class="bulleted-list"><li style="list-style-type:disc">유용한 정보를 유지할 확률이 높음</li></ul><ul id="e05ddfcb-7351-4c6b-a057-24359da97ad9" class="bulleted-list"><li style="list-style-type:disc">뉴런 2개 - 2D 데이터만 출력 가능 → 3D 데이터 처리 : 일부 정보 손실</li></ul><p id="f4a79ab4-5747-4ea0-8972-275c960b6f53" class="">
</p><p id="ff8a1db8-ba38-4143-a267-d681dd6ffbf5" class=""><strong>🔥 </strong><span style="border-bottom:0.05em solid"><strong>일반적으로 층의 뉴런 수보다 층 수를 늘리는 것이 유리</strong></span></p><h3 id="edfc3f7e-2c84-4ee0-bf4a-f26cd6450dc8" class="block-color-blue_background">10.3.3 학습률, 배치 크기 그리고 다른 하이퍼파라미터</h3><p id="4ba25e04-a10c-46db-ba47-5f7bc00ee744" class="">&lt;<em><strong>학습률&gt;</strong></em></p><p id="87031170-cac3-4195-9f48-ff37fb13dca9" class="">가장 중요한 하이퍼파라미터</p><p id="77c33b50-2086-49b1-a921-d0d80bbaf63d" class="">최적의 학습률 = 최대 학습률의 절반 정도</p><ul id="50e981fc-5bb7-4e1c-adee-c3131b1db70d" class="bulleted-list"><li style="list-style-type:disc">낮은 학습률 - - - 매우 큰 학습률까지 반복 훈련 <mark class="highlight-gray">(반복마다 일정한 값을 학습률에 곱하기)</mark></li></ul><ul id="4b0a1114-471a-4e01-a332-bba319d91a82" class="bulleted-list"><li style="list-style-type:disc">손실이 다시 상승하는 지점 有 → <span style="border-bottom:0.05em solid">이 지점에서 조금 아래 = 최적의 학습률
</span>                                                 <mark class="highlight-gray">상승점보다 약 10배 낮은 지점</mark></li></ul><p id="9d17a6ce-4503-4617-b566-37b6448f272c" class="">
</p><p id="e74bae87-6add-46bd-8292-b2b6b8d7e522" class=""><em><strong>&lt;옵티마이저&gt;</strong></em></p><p id="772612f7-9f5d-49f6-bbb6-7c8bea236b50" class="">11장에서</p><p id="fdbfc437-5e81-46cf-88e1-c247903660cc" class="">...</p><p id="5d881e05-609e-4970-931f-d7a63ec44e28" class=""><em><strong>&lt;배치 크기&gt;</strong></em></p><p id="0f02cc16-031f-4417-bbbf-cf53aa4fcf75" class="">모델 성능과 훈련 시간에 큰 영향</p><p id="43841cc5-193a-479d-8280-a74e23283af3" class="">큰 배치 크기 → 하드웨어 가속기(ex. GPU)를 효율적으로 활용
                        초당 더 많은 샘플 처리 가능 !</p><ul id="67e697d8-02fb-468b-a9e6-96c467af2f3f" class="bulleted-list"><li style="list-style-type:disc">GPU 램에 맞는 가장 큰 배치 크기 사용 권장</li></ul><ul id="6648a72a-a4e6-48f9-bae4-b15aa8c0dc7e" class="bulleted-list"><li style="list-style-type:disc">실전에서는 훈련 초기 불안정한 훈련 주의 - -</li></ul><ul id="8faa7738-6f99-4189-9fd0-2f8a4c47b732" class="bulleted-list"><li style="list-style-type:disc">2 ~ 32의 미니 배치를 사용하는 것이 바람직하다(너무 큰 배치 크기는 일반화 성능에 영향을 미친다)</li></ul><p id="77387afb-578c-4597-b420-8683bf06e165" class="">                                     ↑↓</p><ul id="00bd2189-b4e3-4310-889a-0f19d52504ad" class="bulleted-list"><li style="list-style-type:disc">아니다! 다양한 기법으로 매우 큰 배치 크기(8,192까지)도 사용할 수 있다!</li></ul><p id="8486885c-a899-4f66-b1e1-50316bb775e6" class="">⇒ 전략) <span style="border-bottom:0.05em solid">학습률 예열을 사용해 큰 배치 크기를 시도</span> - <del>불안정적이면, → 작은 배치 크기 사용</del></p><p id="62e15f60-baec-4bdc-ab0c-d80e5b513d01" class="">                                                                           </p><p id="537c10bd-e876-45e5-bc9a-f6348a226d11" class=""><em><strong>&lt;활성화 함수&gt;</strong></em></p><p id="51c8d1bf-227e-402e-8e5e-8aa9f631a166" class="">일반적으로 RELU가 모든 은닉층에 좋은 기본값</p><p id="8faccbd9-1e78-4b18-9b8b-efb635b561b3" class="">
</p><p id="3707ed61-97a9-4a23-9151-b05585cb5ea8" class=""><em><strong>&lt;반복 횟수&gt;</strong></em></p><p id="725ab81c-f4a0-4e42-b52c-99526b8bd6b0" class="">대부분 이 값은 튜닝이 필요 없음</p><p id="be415d8c-2e5c-463a-9ecb-55601465e06d" class="">대신 <span style="border-bottom:0.05em solid">조기 종료 사용</span></p><h2 id="0b1dade7-3890-483a-a4e9-5ef7b5ffb948" class="block-color-gray_background">10.4 연습문제</h2><figure id="5edd7a93-2b42-434e-9a2a-8c08a66b8075" class="link-to-page"><a href="Week1%208e3cc69f4e08483293a27c2b56187454/%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%89%E1%85%B3%E1%86%B8%E1%84%86%E1%85%AE%E1%86%AB%E1%84%8C%E1%85%A6%20%E1%84%91%E1%85%AE%E1%86%AF%E1%84%8B%E1%85%B5%205edd7a932b42434e9a2a8c08a66b8075.html">연습문제 풀이</a></figure><p id="259ecb56-3063-4c5f-a24e-629b7309e3b7" class="">
</p><p id="ccb6b5ef-c613-42ea-9244-29db7bd6cb42" class="">
</p></div></article></body></html>